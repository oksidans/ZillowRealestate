{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#Importing and Initializing the Regressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dataset\n",
    "\n",
    "train = pd.read_csv('zillow/train.csv')\n",
    "\n",
    "#Test for evaluation\n",
    "test = pd.read_csv('zillow/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing typo\n",
    "\n",
    "train = train.replace({\"Exterior2nd\":{\"CmentBd\":\"CemntBd\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Id for further refference\n",
    "Id_train =train['Id']\n",
    "Id_test = test['Id']\n",
    "#Dropping Id from dataset\n",
    "train.drop('Id', axis=1, inplace=True)  #For feature engeneering\n",
    "test.drop('Id', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving SalePrice\n",
    "train = train[train.GrLivArea < 4500]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "y = train['SalePrice'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.drop(['SalePrice'], axis=1)\n",
    "test_features = test\n",
    "df = pd.concat([df, test_features]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MSSubClass'] = df['MSSubClass'].apply(str)\n",
    "df['YrSold'] = df['YrSold'].astype(str)\n",
    "df['MoSold'] = df['MoSold'].astype(str)\n",
    "df['Functional'] = df['Functional'].fillna('Typ') \n",
    "df['Electrical'] = df['Electrical'].fillna(\"SBrkr\") \n",
    "df['KitchenQual'] = df['KitchenQual'].fillna(\"TA\") \n",
    "df[\"PoolQC\"] = df[\"PoolQC\"].fillna(\"None\")\n",
    "df['Exterior1st'] = df['Exterior1st'].fillna(df['Exterior1st'].mode()[0]) \n",
    "df['Exterior2nd'] = df['Exterior2nd'].fillna(df['Exterior2nd'].mode()[0])\n",
    "df['SaleType'] = df['SaleType'].fillna(df['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Garage\n",
    "df['GarageYrBlt'] = df['GarageYrBlt'].fillna(0)\n",
    "df['GarageArea'] = df['GarageArea'].fillna(0)\n",
    "df['GarageCars'] = df['GarageCars'].fillna(0)\n",
    "df['GarageType'] = df['GarageType'].fillna(\"None\")\n",
    "df['GarageFinish'] = df['GarageFinish'].fillna(\"None\")\n",
    "df['GarageQual'] = df['GarageQual'].fillna(\"None\")\n",
    "df['GarageCond'] = df['GarageCond'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basement\n",
    "df['BsmtQual'] = df['BsmtQual'].fillna(\"None\")\n",
    "df['BsmtCond'] = df['BsmtCond'].fillna(\"None\")\n",
    "df['BsmtExposure'] = df['BsmtExposure'].fillna(\"None\")\n",
    "df['BsmtFinType1'] = df['BsmtFinType1'].fillna(\"None\")\n",
    "df['BsmtFinType2'] = df['BsmtFinType2'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSzoning\n",
    "df['MSZoning'] = df.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill none with categorical\n",
    "objects = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == object:\n",
    "        objects.append(i)\n",
    "df.update(df[objects].fillna('None'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill Zero with numerical\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype in numeric_dtypes:\n",
    "        numerics.append(i)\n",
    "\n",
    "        df.update(df[numerics].fillna(0))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "#Fixing skewnes with numerical\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics2 = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype in numeric_dtypes:\n",
    "        numerics2.append(i)\n",
    "skew_features = df[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "\n",
    "for i in skew_index:\n",
    "    df[i] = boxcox1p(df[i], boxcox_normmax(df[i] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding new features and drop non informative\n",
    "\n",
    "df = df.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n",
    "\n",
    "df['YrBltAndRemod']=df['YearBuilt']+df['YearRemodAdd']\n",
    "df['TotalSF']=df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
    "\n",
    "df['Total_sqr_footage'] = (df['BsmtFinSF1'] + df['BsmtFinSF2'] +\n",
    "                                 df['1stFlrSF'] + df['2ndFlrSF'])\n",
    "\n",
    "df['Total_Bathrooms'] = (df['FullBath'] + (0.5 * df['HalfBath']) +\n",
    "                               df['BsmtFullBath'] + (0.5 * df['BsmtHalfBath']))\n",
    "\n",
    "df['Total_porch_sf'] = (df['OpenPorchSF'] + df['3SsnPorch'] +\n",
    "                              df['EnclosedPorch'] + df['ScreenPorch'] +\n",
    "                              df['WoodDeckSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['haspool'] = df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df['has2ndfloor'] = df['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df['hasgarage'] = df['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df['hasbsmt'] = df['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df['hasfireplace'] = df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape  #Combined train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:len(y), :]\n",
    "X_sub = df.iloc[len(y):, :]\n",
    "Z = pd.concat((X,y), axis=1)\n",
    "X.shape, y.shape, X_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Split  training dataset to train and test set\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.13, random_state=42)\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.22, random_state=12)\n",
    "\n",
    "for train_index, test_index in split.split(Z, Z['Neighborhood']):\n",
    "    str_train = Z.iloc[train_index]\n",
    "    str_test   = Z.loc[test_index]\n",
    "    \n",
    "\n",
    "y_train = str_train['SalePrice']\n",
    "y_ver  = str_test['SalePrice']\n",
    "X_train = str_train.drop('SalePrice', axis = 1)\n",
    "X_ver = str_test.drop('SalePrice', axis = 1)\n",
    "X = pd.concat((X_train, X_ver), axis=0)\n",
    "y = pd.concat((y_train, y_ver), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat((X, X_sub), axis=0)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sparse = pd.get_dummies(final).reset_index(drop=True)\n",
    "X = final_sparse.iloc[:len(y), :]\n",
    "X_sub = final_sparse.iloc[len(y):, :]\n",
    "X.shape, y.shape, X_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = [30, 88, 462, 631, 1322]\n",
    "X = X.drop(X.index[outliers])\n",
    "y = y.drop(y.index[outliers])\n",
    "\n",
    "overfit = []\n",
    "for i in X.columns:\n",
    "    counts = X[i].value_counts()\n",
    "    zeros = counts.iloc[0]\n",
    "    if zeros / len(X) * 100 > 99.94:\n",
    "        overfit.append(i)\n",
    "\n",
    "overfit = list(overfit)\n",
    "X = X.drop(overfit, axis=1)\n",
    "X_sub = X_sub.drop(overfit, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape, X_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, X=X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))                                \n",
    "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=5000,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.2,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cv_rmse(ridge)\n",
    "score = cv_rmse(lasso)\n",
    "print(\"LASSO: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(elasticnet)\n",
    "print(\"elastic net: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(svr)\n",
    "print(\"SVR: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(lightgbm)\n",
    "print(\"lightgbm: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(gbr)\n",
    "print(\"gbr: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('START Fit')\n",
    "\n",
    "print('stack_gen')\n",
    "stack_gen_model = stack_gen.fit(np.array(X), np.array(y))\n",
    "\n",
    "print('elasticnet')\n",
    "elastic_model_full_data = elasticnet.fit(X, y)\n",
    "\n",
    "print('Lasso')\n",
    "lasso_model_full_data = lasso.fit(X, y)\n",
    "\n",
    "print('Ridge')\n",
    "ridge_model_full_data = ridge.fit(X, y)\n",
    "\n",
    "print('Svr')\n",
    "svr_model_full_data = svr.fit(X, y)\n",
    "\n",
    "print('GradientBoosting')\n",
    "gbr_model_full_data = gbr.fit(X, y)\n",
    "\n",
    "print('xgboost')\n",
    "xgb_model_full_data = xgboost.fit(X, y)\n",
    "\n",
    "print('lightgbm')\n",
    "lgb_model_full_data = lightgbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_models_predict(X):\n",
    "    return ((0.3 * elastic_model_full_data.predict(X)) + \\\n",
    "            (0.3 * lasso_model_full_data.predict(X)) + \\\n",
    "            (0.4 * ridge_model_full_data.predict(X)) )\n",
    "            #(0.1 * svr_model_full_data.predict(X)) + \\\n",
    "            #(0.1 * gbr_model_full_data.predict(X)) + \\\n",
    "            #(0.15 * xgb_model_full_data.predict(X)) + \\\n",
    "            #(0.1 * lgb_model_full_data.predict(X)) + \\\n",
    "            #(0.3 * stack_gen_model.predict(np.array(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, blend_models_predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predict submission')\n",
    "submission = pd.read_csv(\"zillow/sample_submission.csv\")\n",
    "submission.iloc[:,1] = np.floor(np.expm1(blend_models_predict(X_sub)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Blend with Top Kernels submissions\\n')\n",
    "sub_1 = pd.read_csv('zillow/House_Prices_submit.csv')\n",
    "sub_2 = pd.read_csv('zillow/hybrid_solution.csv')\n",
    "sub_3 = pd.read_csv('zillow/lasso_sol.csv')\n",
    "submission.iloc[:,1] = np.floor((0.25 * np.floor(np.expm1(blend_models_predict(X_sub)))) + \n",
    "                                (0.25 * sub_1.iloc[:,1]) + \n",
    "                                (0.25 * sub_2.iloc[:,1]) + \n",
    "                                (0.25 * sub_3.iloc[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = submission['SalePrice'].quantile(0.005)\n",
    "q2 = submission['SalePrice'].quantile(0.995)\n",
    "submission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\n",
    "submission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
